{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extraction\n",
    "\n",
    "> This module contains new evaluation protocol for UBC Phototour local patch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import os\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "from brown_phototour_revisited.dataset import PhotoTourRevisited\n",
    "from typing import Dict\n",
    "\n",
    "def extract_pytorchinput_descriptors(model: torch.nn.Module,\n",
    "                                desc_name: str,\n",
    "                                subset: str,\n",
    "                                path_to_save_dataset:str = './dataset/',\n",
    "                                path_to_save_descriptors: str = './descriptors/',\n",
    "                                patch_size: int = 32, device: torch.device = torch.device('cpu'))-> Dict:\n",
    "    '''Function, which extracts descriptors and labels required for evaluation'''\n",
    "    allowed_datasets = ['liberty', 'notredame', 'yosemite']\n",
    "    if subset not in allowed_datasets:\n",
    "        raise ValueError(f'subset {subset} should be one of {allowed_datasets}')\n",
    "    BS = 256\n",
    "    transform = tv.transforms.Compose([\n",
    "                tv.transforms.ToPILImage(),\n",
    "                tv.transforms.Resize(patch_size),\n",
    "                tv.transforms.ToTensor()])\n",
    "    kwargs = {} if device is torch.device('cpu') else {'num_workers': 4, 'pin_memory': True}\n",
    "\n",
    "    ds_loader = torch.utils.data.DataLoader(\n",
    "             PhotoTourRevisited(root=path_to_save_dataset,\n",
    "                     name=subset,\n",
    "                     download=True,\n",
    "                     transform=transform),\n",
    "                        batch_size=BS,\n",
    "                        shuffle=False, drop_last = False, **kwargs)\n",
    "    num_patches = len(ds_loader.dataset)\n",
    "    if not os.path.isdir(path_to_save_descriptors):\n",
    "        os.makedirs(path_to_save_descriptors)\n",
    "    DESC_NAME = f'{desc_name}_{patch_size}px_{subset}'\n",
    "    desc_fname = f'{path_to_save_descriptors}/{DESC_NAME}.npy'\n",
    "    labels_fname = f'{path_to_save_descriptors}/{DESC_NAME}_labels.npy'\n",
    "    img_labels_fname = f'{path_to_save_descriptors}/{DESC_NAME}_imglabels.npy'\n",
    "    if os.path.isfile(desc_fname):\n",
    "        print (f\"{desc_fname} already exists, loading\")\n",
    "        descriptors = np.load(desc_fname)\n",
    "        labels = np.load(labels_fname)\n",
    "        img_labels = np.load(img_labels_fname)\n",
    "        assert len(descriptors) == len(labels)\n",
    "        assert len(descriptors) == len(img_labels)\n",
    "        return {\"descriptors\": descriptors,\n",
    "               \"labels\": labels,\n",
    "               \"img_idxs\": img_labels}\n",
    "    labels, img_labels =  np.zeros((num_patches)), np.zeros((num_patches))\n",
    "    descriptors = None\n",
    "    with torch.no_grad():\n",
    "        count = 0\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        for patch, label, img_label in progress_bar(ds_loader):\n",
    "            desc = model(patch.to(device))\n",
    "            bs = len(patch)\n",
    "            if descriptors is None:\n",
    "                dim = desc.size(1)\n",
    "                descriptors = np.zeros((num_patches,dim))\n",
    "            descriptors[count:count+bs] = desc.cpu().detach().numpy()\n",
    "            labels[count:count+bs] = label\n",
    "            img_labels[count:count+bs] = img_label\n",
    "            count+=bs\n",
    "    np.save(desc_fname, descriptors)\n",
    "    np.save(labels_fname, labels)\n",
    "    np.save(img_labels_fname, img_labels)\n",
    "    return {\"descriptors\": descriptors,\n",
    "               \"labels\": labels,\n",
    "               \"img_idxs\": img_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_numpyinput_descriptors(model,\n",
    "                                desc_name: str,\n",
    "                                subset: str,\n",
    "                                path_to_save_dataset:str = './dataset/',\n",
    "                                path_to_save_descriptors: str = './descriptors/',\n",
    "                                patch_size: int = 32)-> Dict:\n",
    "    '''Function, which extracts descriptors and labels required for evaluation'''\n",
    "    allowed_datasets = ['liberty', 'notredame', 'yosemite']\n",
    "    if subset not in allowed_datasets:\n",
    "        raise ValueError(f'subset {subset} should be one of {allowed_datasets}')\n",
    "    BS = 1\n",
    "    transform = tv.transforms.Compose([\n",
    "                tv.transforms.ToPILImage(),\n",
    "                tv.transforms.Resize(patch_size),\n",
    "                tv.transforms.ToTensor()])\n",
    "    ds_loader = torch.utils.data.DataLoader(\n",
    "             PhotoTourRevisited(root=path_to_save_dataset,\n",
    "                     name=subset,\n",
    "                     download=True,\n",
    "                     transform=transform),\n",
    "                        batch_size=BS,\n",
    "                        shuffle=False, drop_last = False)\n",
    "    num_patches = len(ds_loader.dataset)\n",
    "    if not os.path.isdir(path_to_save_descriptors):\n",
    "        os.makedirs(path_to_save_descriptors)\n",
    "    DESC_NAME = f'{desc_name}_{patch_size}px_{subset}'\n",
    "    desc_fname = f'{path_to_save_descriptors}/{DESC_NAME}.npy'\n",
    "    labels_fname = f'{path_to_save_descriptors}/{DESC_NAME}_labels.npy'\n",
    "    img_labels_fname = f'{path_to_save_descriptors}/{DESC_NAME}_imglabels.npy'\n",
    "    if os.path.isfile(desc_fname):\n",
    "        print (f\"{desc_fname} already exists, loading\")\n",
    "        descriptors = np.load(desc_fname)\n",
    "        labels = np.load(labels_fname)\n",
    "        img_labels = np.load(img_labels_fname)\n",
    "        assert len(descriptors) == len(labels)\n",
    "        assert len(descriptors) == len(img_labels)\n",
    "        return {\"descriptors\": descriptors,\n",
    "               \"labels\": labels,\n",
    "               \"img_idxs\": img_labels}\n",
    "    labels, img_labels =  np.zeros((num_patches)), np.zeros((num_patches))\n",
    "    descriptors = None\n",
    "    count = 0\n",
    "    for patch, label, img_label in progress_bar(ds_loader):\n",
    "        desc = model(patch.detach().cpu().view(patch_size, patch_size).numpy())\n",
    "        if descriptors is None:\n",
    "            if len(desc.shape) == 1:\n",
    "                dim = desc.shape[0]\n",
    "            else:\n",
    "                dim = desc.shape[1]\n",
    "            descriptors = np.zeros((num_patches,dim))\n",
    "        descriptors[count:count+BS] = desc.reshape(BS, dim)\n",
    "        labels[count:count+BS] = label\n",
    "        img_labels[count:count+BS] = img_label\n",
    "        count+=BS\n",
    "    np.save(desc_fname, descriptors)\n",
    "    np.save(labels_fname, labels)\n",
    "    np.save(img_labels_fname, img_labels)\n",
    "    return {\"descriptors\": descriptors,\n",
    "               \"labels\": labels,\n",
    "               \"img_idxs\": img_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
