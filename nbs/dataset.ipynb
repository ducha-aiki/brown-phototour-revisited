{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n",
    "\n",
    "> This module contains image index-aware UBC Phototour dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Any, Callable, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import PhotoTour\n",
    "from torchvision.datasets.phototour import read_image_file, read_info_file\n",
    "\n",
    "\n",
    "from torchvision.datasets.utils import download_url\n",
    "\n",
    "class PhotoTourRevisited(torchvision.datasets.PhotoTour):\n",
    "    \"\"\"`Learning Local Image Descriptors Data <http://phototour.cs.washington.edu/patches/default.htm>`_ Dataset\n",
    "    with for new evaluation protocol.\n",
    "    Args:\n",
    "        root (string): Root directory where images are.\n",
    "        name (string): Name of the dataset to load.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "    \"\"\"\n",
    "    img_info_files = 'interest.txt'\n",
    "    def __init__(\n",
    "            self, root: str, name: str,\n",
    "            transform: Optional[Callable] = None, download: bool = False) -> None:\n",
    "        super(PhotoTourRevisited, self).__init__(root, name, False, transform, download)\n",
    "        # load the serialized data\n",
    "        self.data, self.labels, self.img_idxs = torch.load(self.data_file)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Union[torch.Tensor, Tuple[Any, Any, torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (patch, label, img_idx)\n",
    "        \"\"\"\n",
    "        data = self.data[index]\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "        if self.train:\n",
    "            return data\n",
    "        return data, self.labels[index], self.img_idxs[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.lens[self.name]\n",
    "\n",
    "    def download(self) -> None:\n",
    "        if self._check_datafile_exists():\n",
    "            print('# Found cached data {}'.format(self.data_file))\n",
    "            return\n",
    "\n",
    "        if not self._check_downloaded():\n",
    "            # download files\n",
    "            url = self.urls[self.name][0]\n",
    "            filename = self.urls[self.name][1]\n",
    "            md5 = self.urls[self.name][2]\n",
    "            fpath = os.path.join(self.root, filename)\n",
    "\n",
    "            download_url(url, self.root, filename, md5)\n",
    "\n",
    "            print('# Extracting data {}\\n'.format(self.data_down))\n",
    "\n",
    "            import zipfile\n",
    "            with zipfile.ZipFile(fpath, 'r') as z:\n",
    "                z.extractall(self.data_dir)\n",
    "\n",
    "            os.unlink(fpath)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('# Caching data {}'.format(self.data_file))\n",
    "\n",
    "        dataset = (\n",
    "            read_image_file(self.data_dir, self.image_ext, self.lens[self.name]),\n",
    "            read_info_file(self.data_dir, self.info_file),\n",
    "            read_interest_file(self.data_dir, self.img_info_files)\n",
    "        )\n",
    "\n",
    "        with open(self.data_file, 'wb') as f:\n",
    "            torch.save(dataset, f)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return \"Split: Test\"\n",
    "\n",
    "\n",
    "def read_interest_file(data_dir: str, info_file: str) -> torch.Tensor:\n",
    "    \"\"\"Return a Tensor containing the list of image ids\n",
    "       Read the file and keep only the ID of the image point.\n",
    "    \"\"\"\n",
    "    img_idxs = []\n",
    "    with open(os.path.join(data_dir, info_file), 'r') as f:\n",
    "        img_idxs = [int(line.split()[0]) for line in f]\n",
    "    return torch.LongTensor(img_idxs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
