{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# benchmarking\n",
    "\n",
    "> This module contains new evaluation protocol for UBC Phototour local patch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "from scipy.spatial.distance import cdist, hamming\n",
    "from sklearn.metrics.pairwise import paired_distances\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def evaluate_mAP_snn_based(descriptors:np.array,\n",
    "                           labels:np.array,\n",
    "                           img_labels:np.array, \n",
    "                           path_to_save_mAP: str,\n",
    "                           backend:str ='numpy', distance:str ='euclidean'):\n",
    "    '''Function to calculate mean average precision, over per-image based matching using Lowe SNN ratio.'''\n",
    "    if os.path.isfile(path_to_save_mAP):\n",
    "        print (f\"Found saved results {path_to_save_mAP}, loading\")\n",
    "        res = np.load(path_to_save_mAP)\n",
    "        return res\n",
    "    backends = ['numpy', 'pytorch-cuda']\n",
    "    if backend not in backends:\n",
    "        raise ValueError(f'backend {backend} should one of {backends}')\n",
    "    possible_distances = ['euclidean', 'hamming']\n",
    "    if distance == 'euclidean':\n",
    "        p=2\n",
    "    elif distance == 'hamming':\n",
    "        p=0\n",
    "    else:\n",
    "        raise ValueError(f'distance {distance} should one of {possible_distances}')    \n",
    "    APs = []\n",
    "    unique_img_labels = sorted(np.unique(img_labels))\n",
    "    for img_idx in progress_bar(unique_img_labels):\n",
    "        current_batch = img_labels == img_idx\n",
    "        cur_descs = descriptors[current_batch]\n",
    "        if backend == 'pytorch-cuda':\n",
    "            import torch\n",
    "            dev = torch.device('cpu')\n",
    "            try:\n",
    "                if torch.cuda.is_available():\n",
    "                    dev = torch.device('cuda')\n",
    "            except:\n",
    "                dev = torch.device('cpu')\n",
    "            cur_descs = torch.from_numpy(cur_descs).to(dev).float()  \n",
    "        cur_labels = labels[current_batch]\n",
    "        NN = cur_labels.shape[0]\n",
    "        pos_labels_repeat = np.broadcast_to(cur_labels.reshape(1,-1),(NN,NN))\n",
    "        pos_mask = (pos_labels_repeat == pos_labels_repeat.T)\n",
    "        pos_mask_not_anchor = pos_mask != np.eye(NN, dtype=np.bool)\n",
    "        neg_idx = np.zeros((NN), dtype=np.int32)\n",
    "        if NN > 1000: # To avoid OOM, we will find hard negative in batches\n",
    "            bs1 = 128\n",
    "            nb = (NN // bs1)  \n",
    "            for i in range(nb):\n",
    "                st = i*bs1\n",
    "                fin = min(NN, (i+1)*bs1)\n",
    "                if fin == st:\n",
    "                    break\n",
    "                if backend == 'pytorch-cuda':\n",
    "                    dm = torch.cdist(cur_descs[st:fin], cur_descs, p=p) +\\\n",
    "                            1000.0 * torch.from_numpy(pos_mask[st:fin]).to(device=dev, dtype=cur_descs.dtype) + \\\n",
    "                            1000.0 * torch.eye(NN, device=dev, dtype=torch.bool)[st:fin].float()\n",
    "                    min_neg_idxs = torch.min(dm, axis=1)[1].cpu().numpy()\n",
    "                else:\n",
    "                    dm = cdist(cur_descs[st:fin], cur_descs, metric=distance) +\\\n",
    "                            1000.0 * pos_mask[st:fin] + \\\n",
    "                            1000.0 * np.eye(NN, dtype=np.bool)[st:fin]\n",
    "                    min_neg_idxs = np.argmin(dm, axis=1)\n",
    "                neg_idx[st:fin] = min_neg_idxs\n",
    "        # We want to create all possible anchor-positive combinations\n",
    "        pos_idxs = np.broadcast_to(np.arange(NN).reshape(1,-1),(NN,NN))[pos_mask_not_anchor]\n",
    "        anc_idxs = np.nonzero(pos_mask_not_anchor)[0]\n",
    "        pos_mask = None\n",
    "        neg_idxs = neg_idx[anc_idxs]\n",
    "        if backend == 'pytorch-cuda':\n",
    "            pos_dists = torch.nn.functional.pairwise_distance(cur_descs[anc_idxs], cur_descs[pos_idxs], p=p).detach().cpu().numpy()\n",
    "            neg_dists = torch.nn.functional.pairwise_distance(cur_descs[anc_idxs], cur_descs[neg_idxs], p=2).detach().cpu().numpy()\n",
    "        else:\n",
    "            if distance == 'hamming':\n",
    "                pos_dists = paired_distances(cur_descs[anc_idxs], cur_descs[pos_idxs], metric=hamming)\n",
    "                neg_dists = paired_distances(cur_descs[anc_idxs], cur_descs[neg_idxs], metric=hamming)\n",
    "            else:\n",
    "                pos_dists = paired_distances(cur_descs[anc_idxs], cur_descs[pos_idxs], metric=distance)\n",
    "                neg_dists = paired_distances(cur_descs[anc_idxs], cur_descs[neg_idxs], metric=distance)\n",
    "        correct = pos_dists <= neg_dists\n",
    "        snn = np.minimum(pos_dists,neg_dists) / np.maximum(pos_dists,neg_dists)\n",
    "        snn[np.isnan(snn)] = 1.0\n",
    "        ap = average_precision_score(correct, 1-snn)\n",
    "        APs.append(ap)\n",
    "        pos_mask = None\n",
    "        pos_mask_not_anchor = None\n",
    "        cur_descs = None\n",
    "        pos_labels_repeat = None\n",
    "        dm = None\n",
    "        gc.collect()\n",
    "    res = np.array(APs).mean()\n",
    "    if not os.path.isdir(os.path.dirname(path_to_save_mAP)):\n",
    "        os.makedirs(os.path.dirname(path_to_save_mAP))\n",
    "    np.save(path_to_save_mAP, res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from brown_phototour_revisited.extraction import *\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_cached_results(desc_name: str,\n",
    "                    learned_on: list = ['3rdparty'],\n",
    "                    path_to_save_dataset:str = './dataset/',\n",
    "                    path_to_save_descriptors: str = './descriptors/',\n",
    "                    path_to_save_mAP: str = './mAP/',\n",
    "                    patch_size: int = 32):\n",
    "    '''Function, which checks, if the descriptor was already evaluated, and if yes - loads it'''\n",
    "    subsets = ['liberty', 'notredame', 'yosemite']\n",
    "    results = defaultdict(dict)\n",
    "    for train_ds in learned_on:    \n",
    "        for subset in subsets:\n",
    "            if train_ds == '3rdparty':\n",
    "                load_path = f'{path_to_save_mAP}/{desc_name}_PS{patch_size}_3rdparty_{subset}.npy'\n",
    "            else:\n",
    "                load_path = f'{path_to_save_mAP}/{desc_name}_PS{patch_size}_learned{train_ds}_{subset}.npy'\n",
    "            if os.path.isfile(load_path):\n",
    "                print (f\"Found saved results {load_path}, loading\")\n",
    "                mAP = np.load(load_path)\n",
    "                results[train_ds][subset] = mAP\n",
    "                print (f'{desc_name} trained on {learned_on} PS = {patch_size} mAP on {subset} = {mAP:.5f}')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from brown_phototour_revisited.extraction import *\n",
    "from collections import defaultdict\n",
    "\n",
    "def full_evaluation(models,\n",
    "                    desc_name: str,\n",
    "                    path_to_save_dataset:str = './dataset/',\n",
    "                    path_to_save_descriptors: str = './descriptors/',\n",
    "                    path_to_save_mAP: str = './mAP/',\n",
    "                    patch_size: int = 32, \n",
    "                    device: str = 'cpu',\n",
    "                    backend='numpy',\n",
    "                    distance='euclidean'):\n",
    "    '''Function, which performs descriptor extraction and evaluation on all datasets.\n",
    "    models can be either torch.nn.Module or dict with keys ['liberty', 'notredame', 'yosemite'],\n",
    "    denoting datasets, each model was trained on resp.'''\n",
    "    subsets = ['liberty', 'notredame', 'yosemite']\n",
    "    if type(models) is dict:\n",
    "        results = load_cached_results(desc_name,\n",
    "                                      [x for x in models.keys()],\n",
    "                                      path_to_save_dataset,\n",
    "                                      path_to_save_descriptors,\n",
    "                                      path_to_save_mAP,\n",
    "                                      patch_size)\n",
    "        for learned_on, model in models.items():\n",
    "            for subset in subsets:\n",
    "                if subset == learned_on:\n",
    "                    continue\n",
    "                if learned_on in results:\n",
    "                    if subset in results:\n",
    "                        continue\n",
    "                try:\n",
    "                    desc_dict = extract_pytorchinput_descriptors(model,\n",
    "                                    desc_name + '_' + learned_on,\n",
    "                                    subset = subset, \n",
    "                                    path_to_save_dataset = path_to_save_dataset,\n",
    "                                    path_to_save_descriptors = path_to_save_descriptors,\n",
    "                                    patch_size = patch_size, \n",
    "                                    device = device)\n",
    "                except:\n",
    "                    desc_dict = extract_numpyinput_descriptors(model,\n",
    "                                    desc_name + '_' + learned_on,\n",
    "                                    subset= subset, \n",
    "                                    path_to_save_dataset = path_to_save_dataset,\n",
    "                                    path_to_save_descriptors = path_to_save_descriptors,\n",
    "                                    patch_size = patch_size)                    \n",
    "                mAP = evaluate_mAP_snn_based(desc_dict['descriptors'],\n",
    "                             desc_dict['labels'], \n",
    "                             desc_dict['img_idxs'],\n",
    "                             path_to_save_mAP=f'{path_to_save_mAP}/{desc_name}_PS{patch_size}_learned{learned_on}_{subset}.npy',\n",
    "                             backend=backend,\n",
    "                             distance=distance)\n",
    "                results[learned_on][subset] = mAP\n",
    "                print (f'{desc_name} trained on {learned_on} PS = {patch_size} mAP on {subset} = {mAP:.5f}')\n",
    "    else:\n",
    "        model = models\n",
    "        results = load_cached_results(desc_name,\n",
    "                                      ['3rdparty'],\n",
    "                                      path_to_save_dataset,\n",
    "                                      path_to_save_descriptors,\n",
    "                                      path_to_save_mAP,\n",
    "                                      patch_size)\n",
    "        for subset in subsets:\n",
    "            if '3rdparty' in results:\n",
    "                if subset in results['3rdparty']:\n",
    "                    continue\n",
    "            try:\n",
    "                desc_dict = extract_pytorchinput_descriptors(model,\n",
    "                                desc_name + '_3rdparty' ,\n",
    "                                subset= subset, \n",
    "                                path_to_save_dataset = path_to_save_dataset,\n",
    "                                path_to_save_descriptors = path_to_save_descriptors,\n",
    "                                patch_size = patch_size, \n",
    "                                device = device)\n",
    "            except:\n",
    "                desc_dict = extract_numpyinput_descriptors(model,\n",
    "                                desc_name + '_3rdparty' ,\n",
    "                                subset= subset, \n",
    "                                path_to_save_dataset = path_to_save_dataset,\n",
    "                                path_to_save_descriptors = path_to_save_descriptors,\n",
    "                                patch_size = patch_size)\n",
    "            mAP = evaluate_mAP_snn_based(desc_dict['descriptors'],\n",
    "                         desc_dict['labels'], \n",
    "                         desc_dict['img_idxs'],\n",
    "                         path_to_save_mAP=f'{path_to_save_mAP}/{desc_name}_PS{patch_size}_3rdparty_{subset}.npy',\n",
    "                         backend=backend,\n",
    "                         distance=distance)\n",
    "            results['3rdparty'][subset] = mAP\n",
    "            print (f'{desc_name} trained on 3rdparty PS = {patch_size} mAP on {subset} = {mAP:.5f}')        \n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Dict\n",
    "def nice_results_3rdparty(desc_name:str, res_dict:Dict):\n",
    "    '''Returns formatted string with results'''\n",
    "    if 'liberty' in res_dict:\n",
    "        lib = f'{(100*res_dict[\"liberty\"]):.2f}'\n",
    "    else:\n",
    "        lib = '-----'\n",
    "    if 'notredame' in res_dict:\n",
    "        notre = f'{(100*res_dict[\"notredame\"]):.2f}'\n",
    "    else:\n",
    "        notre = '-----'\n",
    "    if 'yosemite' in res_dict:\n",
    "        yos = f'{(100*res_dict[\"yosemite\"]):.2f}'\n",
    "    else:\n",
    "        yos = '-----'\n",
    "    res = f'{desc_name[:20].ljust(20)}   {yos}              {notre}               {lib} '\n",
    "    return res\n",
    "\n",
    "\n",
    "def nice_results_Brown(desc_name:str, res_dict:Dict) -> str:\n",
    "    '''Returns formatted string with results'''\n",
    "    NA = '-----'\n",
    "    lib_yos, lib_notre, yos_notre, yos_lib, notre_lib, notre_yos = NA,NA,NA,NA,NA,NA\n",
    "    if 'liberty' in res_dict:\n",
    "        cr = res_dict['liberty']\n",
    "        if 'notredame' in cr:\n",
    "            lib_notre = f'{(100*cr[\"notredame\"]):.2f}'\n",
    "        else:\n",
    "            lib_notre = NA\n",
    "        if 'yosemite' in cr:\n",
    "            lib_yos = f'{(100*cr[\"yosemite\"]):.2f}'\n",
    "        else:\n",
    "            lib_yos = NA\n",
    "    if 'notredame' in res_dict:\n",
    "        cr = res_dict['notredame']\n",
    "        if 'liberty' in cr:\n",
    "            notre_lib = f'{(100*cr[\"liberty\"]):.2f}'\n",
    "        else:\n",
    "            notre_lib = NA\n",
    "        if 'yosemite' in cr:\n",
    "            notre_yos = f'{(100*cr[\"yosemite\"]):.2f}'\n",
    "        else:\n",
    "            notre_yos = NA    \n",
    "    if 'yosemite' in res_dict:\n",
    "        cr = res_dict['yosemite']\n",
    "        if 'liberty' in cr:\n",
    "            yos_lib = f'{(100*cr[\"liberty\"]):.2f}'\n",
    "        else:\n",
    "            yos_lib = NA\n",
    "        if 'notredame' in cr:\n",
    "            yos_notre = f'{(100*cr[\"notredame\"]):.2f}'\n",
    "        else:\n",
    "            yos_notre = NA    \n",
    "    \n",
    "    res = f'{desc_name[:20].ljust(18)} {lib_yos}  {notre_yos}        {lib_notre}  {yos_notre}        {notre_lib}  {yos_lib}'\n",
    "    return res\n",
    "\n",
    "def print_results_table(full_res_dict: Dict):\n",
    "    '''Function, which prints nicely formatted table with all results'''\n",
    "    TITLE00 = 'Mean Average Precision wrt Lowe SNN ratio criterion on UBC Phototour Revisited'\n",
    "    sep = '------------------------------------------------------------------------------'\n",
    "    TITLE1 = 'trained on       liberty notredame  liberty yosemite  notredame yosemite'\n",
    "    TITLE2 = 'tested  on           yosemite           notredame            liberty'\n",
    "    print (sep)\n",
    "    print (TITLE00)\n",
    "    print (sep)\n",
    "    print (TITLE1)\n",
    "    print (TITLE2)\n",
    "    print (sep)\n",
    "    for desc_name, desc_results in full_res_dict.items():\n",
    "        if '3rdparty' in desc_results:\n",
    "            if len(desc_results['3rdparty']) == 3:\n",
    "                print (nice_results_3rdparty(desc_name, desc_results['3rdparty']))\n",
    "            else:\n",
    "                print (nice_results_Brown(desc_name, desc_results))\n",
    "        else:\n",
    "            print (nice_results_Brown(desc_name, desc_results))\n",
    "    print (sep)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision wrt Lowe SNN ratio criterion on UBC Phototour Revisited\n",
      "------------------------------------------------------------------------------\n",
      "trained on       liberty notredame  liberty yosemite  notredame yosemite\n",
      "tested  on           yosemite           notredame            liberty\n",
      "------------------------------------------------------------------------------\n",
      "Kornia RootSIFT 32px   58.24              49.07               49.65 \n",
      "OpenCV_LATCH 65px  -----  -----        -----  37.26        -----  39.08\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "res = {'Kornia RootSIFT 32px': \n",
    "        {'3rdparty': {'liberty': 0.49652328,\n",
    "                      'notredame': 0.49066364,\n",
    "                      'yosemite': 0.58237198}},\n",
    "       'OpenCV_LATCH 65px': \n",
    "        {'yosemite': {'liberty': 0.39075459, \n",
    "                      'notredame': 0.37258606}}}\n",
    "print_results_table(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
