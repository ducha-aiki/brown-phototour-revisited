{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# benchmarking\n",
    "\n",
    "> This module contains new evaluation protocol for UBC Phototour local patch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import gc\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "from scipy.spatial.distance import cdist, hamming\n",
    "from sklearn.metrics.pairwise import paired_distances\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def evaluate_mAP_snn_based(descriptors:np.array,\n",
    "                           labels:np.array,\n",
    "                           img_labels:np.array, \n",
    "                           backend:str ='numpy', distance:str ='euclidean'):\n",
    "    '''Function to calculate mean average precision, over per-image based matching using Lowe SNN ratio.'''\n",
    "    backends = ['numpy', 'pytorch-cuda']\n",
    "    if backend not in backends:\n",
    "        raise ValueError(f'backend {backend} should one of {backends}')\n",
    "    possible_distances = ['euclidean', 'hamming']\n",
    "    if distance == 'euclidean':\n",
    "        p=2\n",
    "    elif distance == 'hamming':\n",
    "        p=0\n",
    "    else:\n",
    "        raise ValueError(f'distance {distance} should one of {possible_distances}')    \n",
    "    APs = []\n",
    "    unique_img_labels = sorted(np.unique(img_labels))\n",
    "    for img_idx in progress_bar(unique_img_labels):\n",
    "        current_batch = img_labels == img_idx\n",
    "        cur_descs = descriptors[current_batch]\n",
    "        if backend == 'pytorch-cuda':\n",
    "            import torch\n",
    "            dev = torch.device('cpu')\n",
    "            try:\n",
    "                if torch.cuda.is_available():\n",
    "                    dev = torch.device('cuda')\n",
    "            except:\n",
    "                dev = torch.device('cpu')\n",
    "            cur_descs = torch.from_numpy(cur_descs).to(dev)  \n",
    "        cur_labels = labels[current_batch]\n",
    "        NN = cur_labels.shape[0]\n",
    "        pos_labels_repeat = np.broadcast_to(cur_labels.reshape(1,-1),(NN,NN))\n",
    "        pos_mask = (pos_labels_repeat == pos_labels_repeat.T)\n",
    "        pos_mask_not_anchor = pos_mask != np.eye(NN, dtype=np.bool)\n",
    "        neg_idx = np.zeros((NN), dtype=np.int32)\n",
    "        if NN > 1000: # To avoid OOM, we will find hard negative in batches\n",
    "            bs1 = 128\n",
    "            nb = (NN // bs1)  \n",
    "            for i in range(nb):\n",
    "                st = i*bs1\n",
    "                fin = min(NN, (i+1)*bs1)\n",
    "                if fin == st:\n",
    "                    break\n",
    "                if backend == 'pytorch-cuda':\n",
    "                    dm = torch.cdist(cur_descs[st:fin], cur_descs, p=p) +\\\n",
    "                            1000.0 * torch.from_numpy(pos_mask[st:fin]).to(device=dev, dtype=cur_descs.dtype) + \\\n",
    "                            1000.0 * torch.eye(NN, device=dev, dtype=torch.bool)[st:fin].float()\n",
    "                    min_neg_idxs = torch.min(dm, axis=1)[1].cpu().numpy()\n",
    "                else:\n",
    "                    dm = cdist(cur_descs[st:fin], cur_descs, metric=distance) +\\\n",
    "                            1000.0 * pos_mask[st:fin] + \\\n",
    "                            1000.0 * np.eye(NN, dtype=np.bool)[st:fin]\n",
    "                    min_neg_idxs = np.argmin(dm, axis=1)\n",
    "                neg_idx[st:fin] = min_neg_idxs\n",
    "        # We want to create all possible anchor-positive combinations\n",
    "        pos_idxs = np.broadcast_to(np.arange(NN).reshape(1,-1),(NN,NN))[pos_mask_not_anchor]\n",
    "        anc_idxs = np.nonzero(pos_mask_not_anchor)[0]\n",
    "        pos_mask = None\n",
    "        neg_idxs = neg_idx[anc_idxs]\n",
    "        if backend == 'pytorch-cuda':\n",
    "            pos_dists = torch.nn.functional.pairwise_distance(cur_descs[anc_idxs], cur_descs[pos_idxs], p=p).detach().cpu().numpy()\n",
    "            neg_dists = torch.nn.functional.pairwise_distance(cur_descs[anc_idxs], cur_descs[neg_idxs], p=2).detach().cpu().numpy()\n",
    "        else:\n",
    "            if distance == 'hamming':\n",
    "                pos_dists = paired_distances(cur_descs[anc_idxs], cur_descs[pos_idxs], metric=hamming)\n",
    "                neg_dists = paired_distances(cur_descs[anc_idxs], cur_descs[neg_idxs], metric=hamming)\n",
    "            else:\n",
    "                pos_dists = paired_distances(cur_descs[anc_idxs], cur_descs[pos_idxs], metric=distance)\n",
    "                neg_dists = paired_distances(cur_descs[anc_idxs], cur_descs[neg_idxs], metric=distance)\n",
    "        correct = pos_dists <= neg_dists\n",
    "        snn = np.minimum(pos_dists,neg_dists) / np.maximum(pos_dists,neg_dists)\n",
    "        snn[np.isnan(snn)] = 1.0\n",
    "        ap = average_precision_score(correct, 1-snn)\n",
    "        APs.append(ap)\n",
    "        pos_mask = None\n",
    "        pos_mask_not_anchor = None\n",
    "        cur_descs = None\n",
    "        pos_labels_repeat = None\n",
    "        dm = None\n",
    "        gc.collect()\n",
    "    return np.array(APs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from brown_phototour_revisited.extraction import *\n",
    "from collections import defaultdict\n",
    "\n",
    "def full_evaluation(models,\n",
    "                    desc_name: str,\n",
    "                    path_to_save_dataset:str = './dataset/',\n",
    "                    path_to_save_descriptors: str = './descriptors/',\n",
    "                    patch_size: int = 32, \n",
    "                    device: str = 'cpu',\n",
    "                    backend='numpy',\n",
    "                    distance='euclidean'):\n",
    "    '''Function, which performs descriptor extraction and evaluation on all datasets.\n",
    "    models can be either torch.nn.Module or dict with keys ['liberty', 'notredame', 'yosemite'],\n",
    "    denoting datasets, each model was trained on resp.'''\n",
    "    subsets = ['liberty', 'notredame', 'yosemite']\n",
    "    results = defaultdict(dict)\n",
    "    if type(models) is dict:\n",
    "        for learned_on in subsets:\n",
    "            for subset in subsets:\n",
    "                if subset == learned_on:\n",
    "                    continue\n",
    "                desc_dict = extract_pytorchinput_descriptors(model,\n",
    "                                    desc_name + '_' + learned_on,\n",
    "                                    subset= subset, \n",
    "                                    path_to_save_dataset = path_to_save_dataset,\n",
    "                                    path_to_save_descriptors = path_to_save_descriptors,\n",
    "                                    patch_size = patch_size, \n",
    "                                    device = device)\n",
    "                mAP = evaluate_mAP_snn_based(desc_dict['descriptors'],\n",
    "                             desc_dict['labels'], \n",
    "                             desc_dict['img_idxs'],\n",
    "                             backend=backend,\n",
    "                             distance=distance)\n",
    "                results[learned_on][subset] = mAP\n",
    "                print (f'{desc_name} trained on {trained_on} PS = {patch_size} mAP on {subset} = {mAP:.5f}')\n",
    "    else:\n",
    "        model = models\n",
    "        for subset in subsets:\n",
    "            desc_dict = extract_pytorchinput_descriptors(model,\n",
    "                                desc_name + '_3rdparty' ,\n",
    "                                subset= subset, \n",
    "                                path_to_save_dataset = path_to_save_dataset,\n",
    "                                path_to_save_descriptors = path_to_save_descriptors,\n",
    "                                patch_size = patch_size, \n",
    "                                device = device)\n",
    "            mAP = evaluate_mAP_snn_based(desc_dict['descriptors'],\n",
    "                         desc_dict['labels'], \n",
    "                         desc_dict['img_idxs'],\n",
    "                         backend=backend,\n",
    "                         distance=distance)\n",
    "            results[learned_on][subset] = mAP\n",
    "            print (f'{desc_name} trained on 3rdparty PS = {patch_size} mAP on {subset} = {mAP:.5f}')        \n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
