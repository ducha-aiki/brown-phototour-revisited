---

title: benchmarking


keywords: fastai
sidebar: home_sidebar

summary: "This module contains new evaluation protocol for UBC Phototour local patch dataset"
description: "This module contains new evaluation protocol for UBC Phototour local patch dataset"
nb_path: "nbs/benchmarking.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/benchmarking.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="evaluate_mAP_snn_based" class="doc_header"><code>evaluate_mAP_snn_based</code><a href="__main__.py#L10" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>evaluate_mAP_snn_based</code>(<strong><code>descriptors</code></strong>:<code>array</code>, <strong><code>labels</code></strong>:<code>array</code>, <strong><code>img_labels</code></strong>:<code>array</code>, <strong><code>path_to_save_mAP</code></strong>:<code>str</code>, <strong><code>backend</code></strong>:<code>str</code>=<em><code>'numpy'</code></em>, <strong><code>distance</code></strong>:<code>str</code>=<em><code>'euclidean'</code></em>)</p>
</blockquote>
<p>Function to calculate mean average precision, over per-image based matching using Lowe SNN ratio.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="full_evaluation" class="doc_header"><code>full_evaluation</code><a href="__main__.py#L5" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>full_evaluation</code>(<strong><code>models</code></strong>, <strong><code>desc_name</code></strong>:<code>str</code>, <strong><code>path_to_save_dataset</code></strong>:<code>str</code>=<em><code>'./dataset/'</code></em>, <strong><code>path_to_save_descriptors</code></strong>:<code>str</code>=<em><code>'./descriptors/'</code></em>, <strong><code>path_to_save_mAP</code></strong>:<code>str</code>=<em><code>'./mAP/'</code></em>, <strong><code>patch_size</code></strong>:<code>int</code>=<em><code>32</code></em>, <strong><code>device</code></strong>:<code>str</code>=<em><code>'cpu'</code></em>, <strong><code>backend</code></strong>=<em><code>'numpy'</code></em>, <strong><code>distance</code></strong>=<em><code>'euclidean'</code></em>)</p>
</blockquote>
<p>Function, which performs descriptor extraction and evaluation on all datasets.
models can be either torch.nn.Module or dict with keys ['liberty', 'notredame', 'yosemite'],
denoting datasets, each model was trained on resp.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

